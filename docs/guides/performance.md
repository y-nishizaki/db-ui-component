# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€Databricks UI Component Libraryã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ¯ æ¦‚è¦

å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†éš›ã‚„ã€è¤‡æ•°ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åŒæ™‚ã«è¡¨ç¤ºã™ã‚‹éš›ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–

### 1. ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®åˆ¶é™

```python
# å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
def limit_data_size(df, max_rows=10000):
    """ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’åˆ¶é™"""
    if len(df) > max_rows:
        return df.sample(n=max_rows, random_state=42)
    return df

# ä½¿ç”¨ä¾‹
large_df = spark.sql("SELECT * FROM large_table").toPandas()
optimized_df = limit_data_size(large_df, 5000)

chart = ChartComponent(
    data=optimized_df,
    chart_type='line',
    x_column='date',
    y_column='sales',
    title='æœ€é©åŒ–ã•ã‚ŒãŸå£²ä¸Šãƒ‡ãƒ¼ã‚¿'
)
```

### 2. ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„

```python
# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„
def aggregate_time_series(df, time_column='date', value_column='sales', freq='D'):
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„"""
    df[time_column] = pd.to_datetime(df[time_column])
    aggregated = df.groupby(pd.Grouper(key=time_column, freq=freq))[value_column].sum().reset_index()
    return aggregated.dropna()

# ä½¿ç”¨ä¾‹
daily_sales = aggregate_time_series(df, 'date', 'sales', 'D')
chart = ChartComponent(
    data=daily_sales,
    chart_type='line',
    x_column='date',
    y_column='sales',
    title='æ—¥æ¬¡å£²ä¸Šé›†è¨ˆ'
)
```

### 3. ãƒ‡ãƒ¼ã‚¿å‹ã®æœ€é©åŒ–

```python
# ãƒ‡ãƒ¼ã‚¿å‹ã®æœ€é©åŒ–
def optimize_data_types(df):
    """ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›"""
    for col in df.columns:
        if df[col].dtype == 'object':
            # æ–‡å­—åˆ—åˆ—ã®æœ€é©åŒ–
            if df[col].nunique() / len(df) < 0.5:
                df[col] = df[col].astype('category')
        elif df[col].dtype == 'float64':
            # æµ®å‹•å°æ•°ç‚¹æ•°ã®æœ€é©åŒ–
            if df[col].isnull().sum() == 0:
                df[col] = df[col].astype('float32')
        elif df[col].dtype == 'int64':
            # æ•´æ•°ã®æœ€é©åŒ–
            df[col] = pd.to_numeric(df[col], downcast='integer')
    return df

# ä½¿ç”¨ä¾‹
optimized_df = optimize_data_types(df)
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›: {df.memory_usage().sum() / optimized_df.memory_usage().sum():.2f}å€")
```

## ğŸš€ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æœ€é©åŒ–

### 1. é…å»¶ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

```python
# é…å»¶ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®å®Ÿè£…
class LazyChartComponent:
    def __init__(self, data, **kwargs):
        self.data = data
        self.kwargs = kwargs
        self._chart = None
    
    def render(self):
        if self._chart is None:
            self._chart = ChartComponent(data=self.data, **self.kwargs)
        return self._chart.render()

# ä½¿ç”¨ä¾‹
lazy_chart = LazyChartComponent(
    data=df,
    chart_type='line',
    x_column='date',
    y_column='sales'
)

# å®Ÿéš›ã«è¡¨ç¤ºã™ã‚‹æ™‚ã¾ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’é…å»¶
displayHTML(lazy_chart.render())
```

### 2. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

```python
import functools

# ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
@functools.lru_cache(maxsize=10)
def create_cached_chart(chart_type, x_column, y_column, title):
    """ãƒãƒ£ãƒ¼ãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    return ChartComponent(
        data=df,
        chart_type=chart_type,
        x_column=x_column,
        y_column=y_column,
        title=title
    )

# ä½¿ç”¨ä¾‹
chart1 = create_cached_chart('line', 'date', 'sales', 'å£²ä¸Šæ¨ç§»')
chart2 = create_cached_chart('line', 'date', 'sales', 'å£²ä¸Šæ¨ç§»')  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
```

### 3. ãƒãƒƒãƒå‡¦ç†

```python
# è¤‡æ•°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒãƒƒãƒå‡¦ç†
def render_components_batch(components):
    """è¤‡æ•°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä¸€æ‹¬ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    html_parts = []
    for component in components:
        html_parts.append(component.render())
    return '\n'.join(html_parts)

# ä½¿ç”¨ä¾‹
components = [
    ChartComponent(data=df, chart_type='line', x_column='date', y_column='sales'),
    ChartComponent(data=df, chart_type='bar', x_column='category', y_column='sales'),
    TableComponent(data=df.head(100))
]

batch_html = render_components_batch(components)
displayHTML(batch_html)
```

## ğŸ’¾ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

### 1. ä¸è¦ãªãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤

```python
# ä¸è¦ãªåˆ—ã®å‰Šé™¤
def remove_unnecessary_columns(df, keep_columns):
    """ä¸è¦ãªåˆ—ã‚’å‰Šé™¤"""
    return df[keep_columns]

# ä½¿ç”¨ä¾‹
essential_columns = ['date', 'sales', 'category']
clean_df = remove_unnecessary_columns(df, essential_columns)
```

### 2. ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²å‡¦ç†

```python
# å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²å‡¦ç†
def process_large_data_in_chunks(df, chunk_size=10000):
    """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¦å‡¦ç†"""
    results = []
    for i in range(0, len(df), chunk_size):
        chunk = df.iloc[i:i+chunk_size]
        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®å‡¦ç†
        processed_chunk = process_chunk(chunk)
        results.append(processed_chunk)
    return pd.concat(results, ignore_index=True)

def process_chunk(chunk):
    """ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†"""
    # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®é›†ç´„å‡¦ç†
    return chunk.groupby('category')['sales'].sum().reset_index()
```

### 3. ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®æœ€é©åŒ–

```python
import gc

# ãƒ¡ãƒ¢ãƒªã®æ˜ç¤ºçš„ãªè§£æ”¾
def optimize_memory():
    """ãƒ¡ãƒ¢ãƒªã®æœ€é©åŒ–"""
    gc.collect()  # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
    
    # å¤§ããªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‰Šé™¤
    large_objects = [obj for obj in gc.get_objects() if sys.getsizeof(obj) > 1000000]
    for obj in large_objects:
        del obj
    
    gc.collect()  # å†åº¦ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³

# ä½¿ç”¨ä¾‹
# å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†å¾Œ
optimize_memory()
```

## âš¡ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–

### 1. HTMLã‚µã‚¤ã‚ºã®æœ€é©åŒ–

```python
# HTMLã‚µã‚¤ã‚ºã®æœ€é©åŒ–
def optimize_html_size(html_content, max_size=1000000):
    """HTMLã‚µã‚¤ã‚ºã‚’æœ€é©åŒ–"""
    if len(html_content) > max_size:
        # ä¸è¦ãªç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤
        import re
        optimized_html = re.sub(r'\s+', ' ', html_content)
        optimized_html = re.sub(r'>\s+<', '><', optimized_html)
        return optimized_html
    return html_content

# ä½¿ç”¨ä¾‹
chart = ChartComponent(data=df, chart_type='line', x_column='date', y_column='sales')
html_content = chart.render()
optimized_html = optimize_html_size(html_content)
displayHTML(optimized_html)
```

### 2. å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã®æœ€é©åŒ–

```python
# å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã®æœ€é©åŒ–
def optimize_external_resources(html_content):
    """å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€é©åŒ–"""
    # CDNã®ä½¿ç”¨
    html_content = html_content.replace(
        'https://cdn.plot.ly/plotly-latest.min.js',
        'https://cdn.jsdelivr.net/npm/plotly.js@2.0.0/dist/plotly.min.js'
    )
    return html_content
```

## ğŸ”§ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¨ç›£è¦–

### 1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ¸¬å®š

```python
import time
import psutil
import os

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
def measure_performance(func, *args, **kwargs):
    """é–¢æ•°ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®š"""
    start_time = time.time()
    start_memory = psutil.Process(os.getpid()).memory_info().rss
    
    result = func(*args, **kwargs)
    
    end_time = time.time()
    end_memory = psutil.Process(os.getpid()).memory_info().rss
    
    execution_time = end_time - start_time
    memory_usage = end_memory - start_memory
    
    print(f"å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
    print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage / 1024 / 1024:.2f}MB")
    
    return result

# ä½¿ç”¨ä¾‹
def create_chart():
    return ChartComponent(data=df, chart_type='line', x_column='date', y_column='sales')

chart = measure_performance(create_chart)
```

### 2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–

```python
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
def monitor_memory_usage():
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    
    print(f"RSS: {memory_info.rss / 1024 / 1024:.2f}MB")
    print(f"VMS: {memory_info.vms / 1024 / 1024:.2f}MB")
    print(f"ä½¿ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().available / 1024 / 1024:.2f}MB")

# ä½¿ç”¨ä¾‹
monitor_memory_usage()
```

## ğŸ“ˆ å®Ÿè·µçš„ãªæœ€é©åŒ–ä¾‹

### 1. å¤§è¦æ¨¡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æœ€é©åŒ–

```python
# å¤§è¦æ¨¡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æœ€é©åŒ–
def create_optimized_dashboard(large_dataset):
    """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    processed_data = optimize_data_types(large_dataset)
    sampled_data = limit_data_size(processed_data, 10000)
    
    # 2. é›†ç´„ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    daily_data = aggregate_time_series(sampled_data, 'date', 'sales', 'D')
    category_data = sampled_data.groupby('category')['sales'].sum().reset_index()
    
    # 3. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ä½œæˆï¼ˆé…å»¶ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼‰
    components = [
        LazyChartComponent(data=daily_data, chart_type='line', x_column='date', y_column='sales'),
        LazyChartComponent(data=category_data, chart_type='pie', x_column='category', y_column='sales'),
        TableComponent(data=sampled_data.head(100))
    ]
    
    # 4. ãƒãƒƒãƒãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    dashboard_html = render_components_batch(components)
    
    # 5. HTMLæœ€é©åŒ–
    optimized_html = optimize_html_size(dashboard_html)
    
    return optimized_html

# ä½¿ç”¨ä¾‹
large_df = spark.sql("SELECT * FROM large_sales_table").toPandas()
dashboard_html = create_optimized_dashboard(large_df)
displayHTML(dashboard_html)
```

### 2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã®æœ€é©åŒ–

```python
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã®æœ€é©åŒ–
class OptimizedRealTimeDashboard:
    def __init__(self, initial_data):
        self.data = initial_data
        self.charts = {}
        self.last_update = time.time()
        self.update_interval = 30  # 30ç§’é–“éš”
    
    def should_update(self):
        """æ›´æ–°ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        return time.time() - self.last_update > self.update_interval
    
    def update_charts(self, new_data):
        """ãƒãƒ£ãƒ¼ãƒˆã‚’æ›´æ–°ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
        if not self.should_update():
            return
        
        # å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å‡¦ç†
        new_records = new_data[new_data['timestamp'] > self.data['timestamp'].max()]
        
        if len(new_records) > 0:
            # æœ€æ–°ã®1000ä»¶ã®ã¿ã‚’ä¿æŒ
            self.data = pd.concat([self.data, new_records]).tail(1000)
            
            # ãƒãƒ£ãƒ¼ãƒˆã®æ›´æ–°
            for chart_name, chart in self.charts.items():
                chart.update_data(self.data)
            
            self.last_update = time.time()
    
    def render(self):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
        return render_components_batch(self.charts.values())

# ä½¿ç”¨ä¾‹
dashboard = OptimizedRealTimeDashboard(initial_data)
# å®šæœŸçš„ã«update_chartsã‚’å‘¼ã³å‡ºã—ã¦æ›´æ–°
```

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](./security.md) - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
- [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ](./deployment.md) - æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤
- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](../troubleshooting/faq.md) - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¢é€£ã®FAQ

## â“ ã‚µãƒãƒ¼ãƒˆ

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

- [ã‚ˆãã‚ã‚‹å•é¡Œ](../troubleshooting/faq.md)
- [ã‚¨ãƒ©ãƒ¼ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](../troubleshooting/errors.md)
- [GitHub Issues](https://github.com/databricks/db-ui-components/issues)